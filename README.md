


# DCGAN on MNIST - Improved Training Version

This project implements a Deep Convolutional Generative Adversarial Network (DCGAN) using TensorFlow and Keras to generate realistic-looking handwritten digits, trained on the MNIST dataset. The model is optimized for better performance on Kaggle and includes GIF generation of output images over training epochs.

## ğŸ“Œ Features

- âœ… DCGAN built with TensorFlow 2.x
- âœ… Improved generator and discriminator architectures
- âœ… Normalized data to range [-1, 1] for better GAN training
- âœ… Image saving at each epoch for visual tracking
- âœ… Automatic checkpointing every 10 epochs
- âœ… Final output: GIF showing generator progress
- âœ… Adjustable batch size and epochs

## ğŸ“ Project Structure

```

â”œâ”€â”€ dcgan\_mnist\_final.py       # Main training script (your provided code)
â”œâ”€â”€ image\_at\_epoch\_\*.png       # Generated images saved after each epoch
â”œâ”€â”€ dcgan.gif                  # Animation of generated images over epochs
â”œâ”€â”€ training\_checkpoints/      # Saved generator/discriminator weights
â”œâ”€â”€ README.md                  # Project documentation

````

## ğŸ“¦ Requirements

Make sure you have the following libraries installed:

```bash
pip install tensorflow matplotlib imageio pillow
````

## â–¶ï¸ How to Run

1. **Clone the repository** (if this is hosted on GitHub):

   ```bash
   git clone https://github.com/yourusername/dcgan-mnist-final.git
   cd dcgan-mnist-final
   ```

2. **Run the training script**:

   ```bash
   python dcgan_mnist_final.py
   ```

3. **Output**:

   * Image grid is saved as `image_at_epoch_XXXX.png` after each epoch.
   * A final GIF of generated images is saved as `dcgan.gif`.

## ğŸ§  Model Architecture

### Generator

* Dense â†’ BatchNorm â†’ LeakyReLU
* Reshape to 7Ã—7Ã—256
* Conv2DTranspose (128) â†’ BN â†’ LeakyReLU
* Conv2DTranspose (64) â†’ BN â†’ LeakyReLU
* Conv2DTranspose (1, tanh)

### Discriminator

* Conv2D (64) â†’ LeakyReLU â†’ Dropout
* Conv2D (128) â†’ LeakyReLU â†’ Dropout
* Flatten â†’ Dense (1)

## ğŸ§ª Training Settings

* **Batch Size**: 128
* **Epochs**: 50
* **Noise Vector Dim**: 100
* **Optimizer**: Adam (lr=1e-4, beta\_1=0.5)

## ğŸ–¼ Sample Results

You can view the final generated images and the progression of training in the `dcgan.gif` animation.

## ğŸ’¾ Checkpoints

Training checkpoints are saved every 10 epochs in the `training_checkpoints` folder and can be used to resume or fine-tune training.

## ğŸ“Š Dataset

* MNIST Handwritten Digits
* Automatically downloaded via TensorFlow's dataset API
* Shape: `(28, 28, 1)`
* Preprocessing: Rescaled to \[-1, 1]

## ğŸ›  Future Improvements

* Add learning rate decay
* Try different normalization techniques
* Use Wasserstein loss for more stable training
* Extend to color image generation (e.g., CIFAR-10)

## ğŸ“ License

This project is open-source and free to use under the MIT License.



```

---

Let me know if you want a **PDF version**, or if you'd like this turned into a GitHub repository with additional files like `requirements.txt`.
```
